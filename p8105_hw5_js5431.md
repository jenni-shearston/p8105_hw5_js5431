p8105\_hw5\_js5431
================
J Shearston
November 5, 2018

-   [Problem 1](#problem-1)
    -   [Read in and tidy data](#read-in-and-tidy-data)
    -   [Spaghetti plot](#spaghetti-plot)
-   [Problem 2](#problem-2)
    -   [Washington Post Homicide Data](#washington-post-homicide-data)
    -   [Total number of homicides and unsolved homicides by city](#total-number-of-homicides-and-unsolved-homicides-by-city)
    -   [Baltimore, MD](#baltimore-md)
    -   [Proportion of unsolved homicides, US](#proportion-of-unsolved-homicides-us)

Problem 1
---------

### Read in and tidy data

Create file name and file path variables.

``` r
file_names = list.files("./data")

paths = tibble(file_names) %>% 
  mutate(file_names = str_c("./data/", file_names))
```

Create functions to read in files and tidy resulting list.

``` r
## read in files
readin = function(x) {
  read_csv(file = x)
}

## tidy observation data
obs_cleanup = function(x){
  gather(x, key = week, value = obs_data, week_1:week_8) %>% 
    mutate(week = str_replace(week, "week_", ""))
}
```

Use `map` to read in and clean the data.

``` r
study_data = 
  paths %>% 
  mutate(data = map(file_names, readin),
         id = str_replace(file_names, "./data/", ""),
         id = str_replace(id, ".csv", ""),
         exp_group = str_detect(id, "exp"),
         data = map(data, obs_cleanup)) %>% 
  select(-file_names)
```

### Spaghetti plot

Figure 1 depicts spaghetti plots for each research subject over time, faceted by study arm. The control group (FALSE facet) has markedly lower observation values over time when compared to the experimental group (TRUE facet). While the control group's numbers remain fairly stable and even slightly decline after eight weeks, with some variation, the experimental group's numbers clearly increase over the eight week period.

``` r
study_data %>% 
  unnest() %>%
  mutate(week = as.numeric(week)) %>% 
  ggplot(aes(x = week, y = obs_data, color = id)) +
  geom_line() +
  facet_grid(~exp_group) +
  labs(
    title = "Figure 1. Observation Value over Time, by Subject",
    x = "Week",
    y = "Observation Value",
    caption = "Control Group = FALSE, Experimental Group = TRUE") +
  theme(legend.position="none")
```

<img src="p8105_hw5_js5431_files/figure-markdown_github/p1 spaghetti plot-1.png" width="90%" />

Problem 2
---------

Read in data.

``` r
hom_data = read_csv("homicide-data.csv")
```

### Washington Post Homicide Data

The Washington Post homicide data contains information on homicides from 50 major US cities, from the years 2007 to 2015. The dataset contains 52179 rows and 12 columns. Variables include a unique identifer for each homicide, homicide related variables including the reported date of the homicide and the case disposition, information about the victim, including the victim's first and last name, age, sex, and race, and geographic location, including the city, state, latitude, and longitude of the homicide.

### Total number of homicides and unsolved homicides by city

``` r
hom_data = hom_data %>%
  mutate(city_state = str_c(city, ", ", state))

unsolved = hom_data %>% 
  group_by(city_state) %>% 
  mutate(unsolv_true = str_detect(disposition, "without|No")) %>% 
  summarise(num_homs = n_distinct(uid),
            num_unsolv_homs = sum(unsolv_true == "TRUE"))

knitr::kable(unsolved)
```

| city\_state        |  num\_homs|  num\_unsolv\_homs|
|:-------------------|----------:|------------------:|
| Albuquerque, NM    |        378|                146|
| Atlanta, GA        |        973|                373|
| Baltimore, MD      |       2827|               1825|
| Baton Rouge, LA    |        424|                196|
| Birmingham, AL     |        800|                347|
| Boston, MA         |        614|                310|
| Buffalo, NY        |        521|                319|
| Charlotte, NC      |        687|                206|
| Chicago, IL        |       5535|               4073|
| Cincinnati, OH     |        694|                309|
| Columbus, OH       |       1084|                575|
| Dallas, TX         |       1567|                754|
| Denver, CO         |        312|                169|
| Detroit, MI        |       2519|               1482|
| Durham, NC         |        276|                101|
| Fort Worth, TX     |        549|                255|
| Fresno, CA         |        487|                169|
| Houston, TX        |       2942|               1493|
| Indianapolis, IN   |       1322|                594|
| Jacksonville, FL   |       1168|                597|
| Kansas City, MO    |       1190|                486|
| Las Vegas, NV      |       1381|                572|
| Long Beach, CA     |        378|                156|
| Los Angeles, CA    |       2257|               1106|
| Louisville, KY     |        576|                261|
| Memphis, TN        |       1514|                483|
| Miami, FL          |        744|                450|
| Milwaukee, wI      |       1115|                403|
| Minneapolis, MN    |        366|                187|
| Nashville, TN      |        767|                278|
| New Orleans, LA    |       1434|                930|
| New York, NY       |        627|                243|
| Oakland, CA        |        947|                508|
| Oklahoma City, OK  |        672|                326|
| Omaha, NE          |        409|                169|
| Philadelphia, PA   |       3037|               1360|
| Phoenix, AZ        |        914|                504|
| Pittsburgh, PA     |        631|                337|
| Richmond, VA       |        429|                113|
| Sacramento, CA     |        376|                139|
| San Antonio, TX    |        833|                357|
| San Bernardino, CA |        275|                170|
| San Diego, CA      |        461|                175|
| San Francisco, CA  |        663|                336|
| Savannah, GA       |        246|                115|
| St. Louis, MO      |       1677|                905|
| Stockton, CA       |        444|                266|
| Tampa, FL          |        208|                 95|
| Tulsa, AL          |          1|                  0|
| Tulsa, OK          |        583|                193|
| Washington, DC     |       1345|                589|

### Baltimore, MD

``` r
results_pt_bmd <- prop.test(x = unsolved$num_unsolv_homs[[3]], n = unsolved$num_homs[[3]])

results_pt_bmd = broom::tidy(results_pt_bmd)
```

For the city of Baltimore, Maryland, a proportion of 0.6455607 homicides remain unsolved, with a confidence interval of 0.6275625 - 0.6631599.

### Proportion of unsolved homicides, US

Creating a function for `prop.test` (plus some tidying), and using a `map` statement to apply it to all cities in the dataset.

``` r
## prop.test function

pt_unsolvhom = function(x){
  prop.test(x = unsolved$num_unsolv_homs[[x]], n = unsolved$num_homs[[x]]) %>% 
    broom::tidy()
  }

## map statement and cleaning

unsolved = unsolved %>% 
  mutate(pt_results = map(1:51, pt_unsolvhom)) %>% 
  unnest() %>% 
  select(-statistic, -p.value, -parameter, -method, -alternative)
```

    ## Warning in prop.test(x = unsolved$num_unsolv_homs[[x]], n = unsolved
    ## $num_homs[[x]]): Chi-squared approximation may be incorrect

Plot: Proportion of unsolved homicides by city

``` r
unsolved %>% 
  filter(city_state != "Tulsa, AL") %>% 
  mutate(city_state = forcats::fct_reorder(city_state, estimate)) %>% 
  ggplot(aes(x = city_state, y = estimate)) +
  geom_point(alpha = .5) +
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high)) +
  labs(
    title = "Figure 2. Proportion of Unsolved Homicides, 50 US Cities",
    x = "Location",
    y = "Prop. Unsolved Homicides",
    caption = "Data from the Washington Post") +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))
```

<img src="p8105_hw5_js5431_files/figure-markdown_github/p2 proptest plot-1.png" width="90%" />

Please note: The city called "Tulsa, AL" was filtered out because it had a homicide of 1 and after a Google search, did not appear to be a real city.
